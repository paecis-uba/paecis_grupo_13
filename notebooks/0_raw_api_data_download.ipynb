{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de datos utilizando Youtube API a través de la cuenta de Google Cloud Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq36uxbY9el8"
   },
   "source": [
    "Instalando el Cliente para Google Api Python Client. Traemos la api-key desde la variable de ambiente usando dotenv\n",
    "Referencias de la API: https://developers.google.com/youtube/v3/docs?hl=es-419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21145,
     "status": "ok",
     "timestamp": 1720262860894,
     "user": {
      "displayName": "Vladyslav Dodonov",
      "userId": "03989027945806646216"
     },
     "user_tz": -120
    },
    "id": "ICsa_xGybDf5",
    "outputId": "ebe10c59-7f9f-4bab-937d-6e619fbb371b"
   },
   "outputs": [],
   "source": [
    "#%pip install google-api-python-client\n",
    "#%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API KEY add:\n",
    "Windows --> \n",
    "setx YOUTUBE_API_KEY \"your_actual_api_key\"\n",
    "Linux --> \n",
    "export YOUTUBE_API_KEY=\"your_actual_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhTrPl3B9nfk"
   },
   "source": [
    "Inicializando la api-key desde la variable de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R1RlgkCAqoRO"
   },
   "outputs": [],
   "source": [
    "# Get the API key from the environment\n",
    "api_key = os.getenv('YOUTUBE_API_KEY')\n",
    "#api_key = \"\" #add the api key as a variable whenever it's good to go\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"Clave de API no encontrada. Asegurate de que esté configurada en el entorno o en el archivo .env.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be9_hSby9sCj"
   },
   "source": [
    "La función principal que ejecuta la llamada a la API para obtener la información de los videos y los comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KTtwckyBFFWP"
   },
   "outputs": [],
   "source": [
    "# Function to fetch comments for a YouTube video along with video information\n",
    "def get_video_comments(video_id, relacion_evento, evento, tipo_evento, condiciones_cuenta, max_retries=5):\n",
    "    # Build a YouTube Data API client\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Fetch video information including duration\n",
    "    video_response = youtube.videos().list(\n",
    "        part='snippet,statistics,contentDetails',\n",
    "        id=video_id\n",
    "    ).execute()\n",
    "\n",
    "    # Extract relevant video data\n",
    "    video_info = video_response['items'][0]['snippet']\n",
    "    video_stats = video_response['items'][0]['statistics']\n",
    "    video_content_details = video_response['items'][0]['contentDetails']\n",
    "    video_data = {\n",
    "        'video_title': video_info['title'],\n",
    "        'channel_title': video_info['channelTitle'],\n",
    "        'video_published_at': video_info['publishedAt'],\n",
    "        'video_views': video_stats.get('viewCount', 0),\n",
    "        'video_likes': video_stats.get('likeCount', 0),\n",
    "        'video_duration': video_content_details['duration'],\n",
    "        'relacion_evento': relacion_evento,\n",
    "        'evento': evento,\n",
    "        'tipo_evento': tipo_evento,\n",
    "        'condiciones_cuenta': condiciones_cuenta\n",
    "    }\n",
    "\n",
    "    # Fetch comments with retry logic\n",
    "    comments_data = []\n",
    "    next_page_token = None\n",
    "    retries = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            comment_response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                maxResults=100,  # Maximum results per page (can adjust as needed)\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "\n",
    "            # Extract comment data\n",
    "            for item in comment_response['items']:\n",
    "                top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "                comment_data = {\n",
    "                    'comment_id': item['snippet']['topLevelComment']['id'],\n",
    "                    'comment': top_comment['textDisplay'],\n",
    "                    'user_id': top_comment['authorChannelId']['value'],\n",
    "                    'user_name': top_comment['authorDisplayName'],\n",
    "                    'comment_time': top_comment['publishedAt'],\n",
    "                    'comment_likes': top_comment['likeCount'],\n",
    "                    'total_reply_count': item['snippet']['totalReplyCount'],\n",
    "                    'is_top_level_comment': True,\n",
    "                }\n",
    "                comment_data.update(video_data)\n",
    "                comments_data.append(comment_data)\n",
    "\n",
    "                # Check for replies\n",
    "                if 'replies' in item:\n",
    "                    for reply in item['replies']['comments']:\n",
    "                        reply_snippet = reply['snippet']\n",
    "                        reply_data = {\n",
    "                            'comment_id': reply['id'],\n",
    "                            'comment': reply_snippet['textDisplay'],\n",
    "                            'user_id': reply_snippet['authorChannelId']['value'],\n",
    "                            'user_name': reply_snippet['authorDisplayName'],\n",
    "                            'comment_time': reply_snippet['publishedAt'],\n",
    "                            'comment_likes': reply_snippet['likeCount'],\n",
    "                            'total_reply_count': 0,  # Replies don't have replies in this structure\n",
    "                            'is_top_level_comment': False,\n",
    "                        }\n",
    "                        reply_data.update(video_data)\n",
    "                        comments_data.append(reply_data)\n",
    "\n",
    "            next_page_token = comment_response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "\n",
    "        except HttpError as e:\n",
    "            if e.resp.status in [500, 503]:\n",
    "                retries += 1\n",
    "                if retries > max_retries:\n",
    "                    print(f\"Se alcanzo el maximo de reintentos para el ID: {video_id}.\")\n",
    "                    break\n",
    "                sleep_time = 2 ** retries  # Exponential backoff\n",
    "                print(f\"Error del servidor (estado  {e.resp.status}), reintentando en {sleep_time} segundos...\")\n",
    "                time.sleep(sleep_time)\n",
    "            else:\n",
    "                print(f\"Ocurrio un error: {e}\")\n",
    "                break\n",
    "\n",
    "    return comments_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAFmbt8A9GY5"
   },
   "source": [
    "Utilizamos la lista de los videos previamente seleccionados para crear tags y asociaciones por canales, eventos y youtubers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input CSV file path\n",
    "ruta_archivo = os.path.join('..', \"data\", \"external\", \"list_links_videos.csv\")\n",
    "input_csv = ruta_archivo\n",
    "\n",
    "# List to store the video info dictionaries\n",
    "videos_info = []\n",
    "\n",
    "# Open the CSV file and read its content\n",
    "with open(input_csv, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        # Create a dictionary for each row with the specified keys\n",
    "        video_entry = {\n",
    "            \"video_id\": row[\"ID\"],\n",
    "            \"relacion_evento\": row[\"Relacion con tema\"],\n",
    "            \"evento\": row[\"Evento cercano\"],\n",
    "            \"tipo_evento\": row[\"Tipo de evento\"],\n",
    "            \"condiciones_cuenta\": row[\"Condicion Cuenta\"]\n",
    "        }\n",
    "        videos_info.append(video_entry)\n",
    "\n",
    "# Now `videos_info` contains the list of dictionaries in the desired format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xrFvm-h9-FS"
   },
   "source": [
    "Creamos un dataframe vacio para guardar los datos de importacion y las clasificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "utQnmdkU9Ugl"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "all_comments_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McehLALD-H85"
   },
   "source": [
    "Iteramos usando la función previamente definida y la lista de los videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQDzbizdF1yh"
   },
   "outputs": [],
   "source": [
    "for video_info in videos_info:\n",
    "    video_id = video_info[\"video_id\"]\n",
    "    relacion_evento = video_info[\"relacion_evento\"]\n",
    "    evento = video_info[\"evento\"]\n",
    "    tipo_evento = video_info[\"tipo_evento\"]\n",
    "    condiciones_cuenta = video_info[\"condiciones_cuenta\"]\n",
    "\n",
    "    # Fetch comments data for the current video\n",
    "    comments_data = get_video_comments(video_id, relacion_evento, evento, tipo_evento, condiciones_cuenta)\n",
    "\n",
    "    # Convert the comments data to a DataFrame\n",
    "    comments_df = pd.DataFrame(comments_data)\n",
    "\n",
    "    # Append the current DataFrame to the main DataFrame\n",
    "    all_comments_df = pd.concat([all_comments_df, comments_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZqdj4g7-JZP"
   },
   "source": [
    "Guardamos el dataframe en un archivo CSV para su posterior exploración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7WXzNAbMF9vZ"
   },
   "outputs": [],
   "source": [
    "# Relative destination for all the notebooks\n",
    "directorio_destino = os.path.join('..', \"data\", \"raw\")\n",
    "archivo_csv = os.path.join(directorio_destino, 'youtube_comments_with_flags_and_replies.csv')\n",
    "\n",
    "# Saving the combined DataFrame to a CSV file with UTF-8 encoding\n",
    "all_comments_df.to_csv(archivo_csv, index=False, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7kMj3ZpwBvkMGdzzYHjGJ",
   "provenance": [
    {
     "file_id": "12lkTL34PQpWT2hMS94Eakrm3X1is13TQ",
     "timestamp": 1720270042728
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
